{"version":3,"file":"bundle.js","sources":["../src/index.js","../src/AudioLevelCalculator.js"],"sourcesContent":["import AudioLevelCalculator from './AudioLevelCalculator'\n\nconst BUFFER_SIZE = 4096\nconst CHANNEL_COUNT = 1\n\nconst AudioContext = window.AudioContext || window.webkitAudioContext\nconst audioContext = new AudioContext({ latencyHint: 'interactive' })\nconst scriptNode = audioContext.createScriptProcessor(\n  BUFFER_SIZE,\n  CHANNEL_COUNT,\n  CHANNEL_COUNT,\n)\nconst gainNode = audioContext.createGain()\ngainNode.gain.value = 0\nscriptNode.connect(gainNode)\ngainNode.connect(audioContext.destination)\n\nlet mediaStream\nlet mediaStreamSourceNode\n\nfunction release() {\n  if (mediaStreamSourceNode) {\n    mediaStreamSourceNode.disconnect()\n    mediaStreamSourceNode = undefined\n  }\n  if (mediaStream) {\n    mediaStream.getTracks().forEach((t) => t.stop())\n    mediaStream = undefined\n  }\n  audioContext.suspend()\n}\n\nexport async function start(cb) {\n  release()\n\n  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })\n  mediaStreamSourceNode = audioContext.createMediaStreamSource(mediaStream)\n  mediaStreamSourceNode.connect(scriptNode)\n  scriptNode.onaudioprocess = (e) => {\n    let samples = e.inputBuffer.getChannelData(0)\n    samples = Int16Array.from(\n      samples.map((x) => (x > 0 ? x * 0x7fff : x * 0x8000)),\n    )\n    let level = AudioLevelCalculator.calculateAudioLevel(\n      samples,\n      BUFFER_SIZE,\n      32767,\n    )\n    cb(level)\n  }\n  audioContext.resume()\n}\n\nexport function stop() {\n  release()\n}\n","export default class AudioLevelCalculator {\n  /**\n   * Calculates the audio level of a signal with specific\n   * <tt>samples</tt>.\n   *\n   * @param samples  the samples whose audio level we need to\n   * calculate.  The samples are specified as an <tt>int</tt>\n   * array starting at <tt>offset</tt>, extending <tt>length</tt>\n   * number of elements, and each <tt>int</tt> element in the\n   * specified range representing a sample whose audio level we\\\n   * need to calculate.  Though a sample is provided in the\n   * form of an <tt>int</tt> value, the sample size in bits\n   * is determined by the caller via <tt>overload</tt>.\n   *\n   * @param length  the length of the signal specified in\n   * <tt>samples<tt>, starting at <tt>offset</tt>.\n   *\n   * @param overload  the overload (point) of <tt>signal</tt>.\n   * For example, <tt>overload</tt> can be {@link Byte#MAX_VALUE}\n   * for 8-bit signed samples or {@link Short#MAX_VALUE} for\n   * 16-bit signed samples.\n   *\n   * @return  the audio level of the specified signal.\n   */\n  static calculateAudioLevel(samples, length, overload) {\n    /*\n     * Calculate the root mean square (RMS) of the signal.\n     */\n    let rms = 0\n\n    for (let offset = 0; offset < length; offset++) {\n      let sample = samples[offset]\n\n      sample /= overload\n      rms += sample * sample\n    }\n    rms = length == 0 ? 0 : Math.sqrt(rms / length)\n\n    /*\n     * The audio level is a logarithmic measure of the\n     * rms level of an audio sample relative to a reference\n     * value and is measured in decibels.\n     */\n    let db\n\n    /*\n     * The minimum audio level permitted.\n     */\n    const MIN_AUDIO_LEVEL = -127\n    /*\n     * The maximum audio level permitted.\n     */\n    const MAX_AUDIO_LEVEL = 0\n\n    if (rms > 0) {\n      /*\n       * The \"zero\" reference level is the overload level,\n       * which corresponds to 1.0 in this calculation, because\n       * the samples are normalized in calculating the RMS.\n       */\n      db = 20 * Math.log10(rms)\n\n      /*\n       * Ensure that the calculated level is within the minimum\n       * and maximum range permitted.\n       */\n      if (db < MIN_AUDIO_LEVEL) db = MIN_AUDIO_LEVEL\n      else if (db > MAX_AUDIO_LEVEL) db = MAX_AUDIO_LEVEL\n    } else {\n      db = MIN_AUDIO_LEVEL\n    }\n\n    let level = Math.round(db)\n    level = (level + 127) / 127\n\n    return level\n  }\n}\n"],"names":["mediaStream","mediaStreamSourceNode","AudioLevelCalculator","calculateAudioLevel","samples","length","overload","db","rms","offset","sample","MIN_AUDIO_LEVEL","Math","sqrt","log10","round","audioContext","window","AudioContext","webkitAudioContext","latencyHint","scriptNode","createScriptProcessor","gainNode","createGain","release","disconnect","undefined","getTracks","forEach","t","stop","suspend","gain","value","connect","destination","cb","navigator","mediaDevices","getUserMedia","audio","createMediaStreamSource","onaudioprocess","e","inputBuffer","getChannelData","Int16Array","from","map","x","level","resume"],"mappings":"6OAiBIA,EACAC,EClBiBC,iDAwBZC,oBAAP,SAA2BC,EAASC,EAAQC,GAM1C,IAFA,IAeIC,EAfAC,EAAM,EAEDC,EAAS,EAAGA,EAASJ,EAAQI,IAAU,CAC9C,IAAIC,EAASN,EAAQK,GAGrBD,IADAE,GAAUJ,GACMI,EAclB,IAAMC,GAAmB,IA2BzB,OAvCAH,EAAgB,GAAVH,EAAc,EAAIO,KAAKC,KAAKL,EAAMH,IAkB9B,GAMRE,EAAK,GAAKK,KAAKE,MAAMN,IAMZG,EAAiBJ,EAAKI,EACtBJ,EAfa,IAeSA,EAfT,GAiBtBA,EAAKI,GAGKC,KAAKG,MAAMR,GACN,KAAO,UDnEtBS,EAAe,IADAC,OAAOC,cAAgBD,OAAOE,oBACb,CAAEC,YAAa,gBAC/CC,EAAaL,EAAaM,sBALZ,KACE,EAAA,GAShBC,EAAWP,EAAaQ,aAQ9B,SAASC,IACHxB,IACFA,EAAsByB,aACtBzB,OAAwB0B,GAEtB3B,IACFA,EAAY4B,YAAYC,QAAQ,SAACC,UAAMA,EAAEC,SACzC/B,OAAc2B,GAEhBX,EAAagB,UAhBfT,EAASU,KAAKC,MAAQ,EACtBb,EAAWc,QAAQZ,GACnBA,EAASY,QAAQnB,EAAaoB,8BAiBFC,OAAI,OAC9BZ,oBAEoBa,UAAUC,aAAaC,aAAa,CAAEC,OAAO,uBACjExC,EAAwBe,EAAa0B,wBADrC1C,MAEsBmC,QAAQd,GAC9BA,EAAWsB,eAAiB,SAACC,GAC3B,IAAIxC,EAAUwC,EAAEC,YAAYC,eAAe,GAC3C1C,EAAU2C,WAAWC,KACnB5C,EAAQ6C,IAAI,SAACC,UAAOA,EAAI,EAAQ,MAAJA,EAAiB,MAAJA,KAE3C,IAAIC,EAAQjD,EAAqBC,oBAC/BC,EA1Cc,KA4Cd,OAEFiC,EAAGc,IAELnC,EAAaoC,WAlBf,sDAsBE3B"}